<!-- <!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Recorder</title>
</head>
<body>
  <h2>ğŸ¤ Recorder (Speech to Text)</h2>
  <button id="start">Start</button>
  <button id="stop" disabled>Stop & Analyze</button>
  <textarea id="text" style="width:100%;height:150px;" placeholder="Transcript will appear here..."></textarea>

  <script>
    let recognition;
    let finalTranscript = '';

    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const textArea = document.getElementById('text');

    if (!('webkitSpeechRecognition' in window)) {
      alert('Your browser does not support speech recognition. Use Chrome.');
    } else {
      recognition = new webkitSpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onresult = (event) => {
        let interim = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          const text = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += text;
          } else {
            interim += text;
          }
        }
        textArea.value = finalTranscript + interim;
      };

      startBtn.onclick = () => {
        finalTranscript = '';
        recognition.start();
        startBtn.disabled = true;
        stopBtn.disabled = false;
      };

      stopBtn.onclick = async () => {
        recognition.stop();
        startBtn.disabled = false;
        stopBtn.disabled = true;

        const transcript = textArea.value;

        try {
        const res = await fetch('https://fyp-2025-kath.vercel.app/api/analyze', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ transcript }), // âœ… æ­£ç¡®å‘é€ JSON æ ¼å¼
        });

        const result = await res.json();
        textArea.value = result.summary || JSON.stringify(result, null, 2);

        // âœ… è¿”å›ç»™æ’ä»¶ï¼ˆå¦‚æœæ˜¯åµŒå…¥ iframe ä¸­ï¼‰
        window.parent?.postMessage({ pluginMessage: result }, '*');
        } catch (err) {
        console.error('âŒ Error during fetch:', err);
        textArea.value = 'âŒ Failed to fetch summary: ' + err.message;
        }
        };

    }
  </script>
</body>
</html> -->



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <style>
    body { font-family: sans-serif; padding: 16px; }
    button { padding: 8px 16px; margin-right: 8px; }
    textarea { width: 100%; height: 200px; margin-top: 12px; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>ğŸ™ï¸ Record Meeting</h2>
  <button id="startBtn">Start</button>
  <button id="stopBtn" disabled>Stop</button>
  <textarea id="textArea" placeholder="Transcript and summary will appear here..."></textarea>

  <script>
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const textArea = document.getElementById('textArea');

  let recorder;
  let chunks = [];

  const params = new URLSearchParams(location.search);
  const sessionId = params.get('session');
  const autoStart = params.get('start') === 'true';

  startBtn.onclick = startRecording;
  stopBtn.onclick = stopRecording;

  if (autoStart) startRecording();

  async function startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recorder = new MediaRecorder(stream);
      chunks = [];

      recorder.ondataavailable = (e) => chunks.push(e.data);

      recorder.onstop = async () => {
        console.log("ğŸ¯ Recording stopped");

        const blob = new Blob(chunks, { type: 'audio/webm' });
        if (blob.size === 0) {
          textArea.value = 'âŒ No audio recorded.';
          return;
        }

        textArea.value = 'ğŸ”„ Uploading and analyzing...';

        const form = new FormData();
        form.append('file', blob, 'audio.webm');

        try {
          const res = await fetch('https://fyp-2025-kath.vercel.app/api/analyze', {
            method: 'POST',
            body: form
          });

          const result = await res.json();
          console.log("âœ… Analysis result:", result);

          textArea.value = `ğŸ“ Transcript:\n${result.transcript}\n\nğŸ§  Summary:\n${result.summary}`;

          // ä¿å­˜åˆ†æç»“æœåˆ°åç«¯
          await fetch('https://fyp-2025-kath.vercel.app/api/save', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              session: sessionId,
              transcript: result.transcript,
              summary: result.summary
            })
          });

        } catch (analyzeErr) {
          console.error('âŒ Analysis or saving failed:', analyzeErr);
          textArea.value = 'âŒ Failed to analyze or save result.';
        }

        startBtn.disabled = false;
        stopBtn.disabled = true;
      };

      recorder.start();
      textArea.value = 'ğŸ™ï¸ Recording...';
      startBtn.disabled = true;
      stopBtn.disabled = false;

    } catch (err) {
      console.error('âŒ Microphone access error:', err);
      textArea.value = 'âŒ Could not access microphone.';
    }
  }

  function stopRecording() {
    if (recorder && recorder.state === 'recording') {
      recorder.stop();
    }
  }
</script>

</body>
</html>


<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <style>
    body { font-family: sans-serif; padding: 16px; }
    button { padding: 8px 16px; margin-right: 8px; }
    textarea { width: 100%; height: 200px; margin-top: 12px; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>ğŸ™ï¸ Record Meeting</h2>
  <button id="startBtn">Start</button>
  <button id="stopBtn" disabled>Stop</button>
  <textarea id="textArea" placeholder="Transcript and summary will appear here..."></textarea>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const textArea = document.getElementById('textArea');

    let recorder;
    let chunks = [];

    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;

    // æ¥æ”¶æ¥è‡ª openerï¼ˆFigma æ’ä»¶ï¼‰çš„æ§åˆ¶æŒ‡ä»¤
    window.addEventListener('message', (event) => {
      const { type } = event.data;
      if (type === 'start-recording') startRecording();
      if (type === 'stop-recording') stopRecording();
    });

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder = new MediaRecorder(stream);
        chunks = [];

        recorder.ondataavailable = (e) => chunks.push(e.data);

        recorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });

          if (blob.size === 0) {
            textArea.value = 'âŒ No audio recorded.';
            return;
          }

          const form = new FormData();
          form.append('file', blob, 'audio.webm');

          try {
            const res = await fetch('https://fyp-2025-kath.vercel.app/api/analyze', {
              method: 'POST',
              body: form
            });

            const result = await res.json();

            textArea.value = `ğŸ“ Transcript:\n${result.transcript}\n\nğŸ§  Summary:\n${result.summary}`;

            // å›ä¼ ç»™ Figma æ’ä»¶çª—å£
            console.log("ready to send")
            window.opener?.postMessage({
              
              pluginMessage: {
                type: 'analyze-transcript',
                transcript: result.transcript,
                summary: result.summary
              }
            }, '*');

          } catch (err) {
            textArea.value = 'âŒ Analysis error: ' + err.message;
            console.log("message sent")
          }

          startBtn.disabled = false;
          stopBtn.disabled = true;
        };

        recorder.start();
        textArea.value = 'ğŸ™ï¸ Recording...';
        startBtn.disabled = true;
        stopBtn.disabled = false;
      } catch (err) {
        console.error('âŒ Could not access microphone:', err);
        textArea.value = 'âŒ Microphone access error';
      }
    }

    function stopRecording() {
      if (recorder && recorder.state === 'recording') {
        recorder.stop();
      }
    }
    window.onload = () => {
      window.opener?.postMessage({ type: 'ready-to-record' }, '*');
    }
  </script>
</body>
</html> -->


<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <style>
    body {
      font-family: sans-serif;
      padding: 16px;
    }

    textarea {
      width: 100%;
      height: 200px;
      resize: none;
      margin-top: 12px;
    }

    button {
      margin-top: 12px;
      padding: 8px 16px;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h2>ğŸ™ï¸ Record Meeting</h2>
  <button id="startBtn">Start</button>
  <button id="stopBtn" disabled>Stop</button>
  <textarea id="textArea" placeholder="Result will show here..."></textarea>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const textArea = document.getElementById('textArea');

    let recorder;
    let chunks = [];

    // æ¥æ”¶æ¥è‡ª ui.html çš„æ¶ˆæ¯æ§åˆ¶
    window.addEventListener('message', async (event) => {
      const { type } = event.data;
      if (type === 'start-recording') {
        startRecording();
      } else if (type === 'stop-recording') {
        stopRecording();
      }
    });

    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder = new MediaRecorder(stream);
        chunks = [];

        recorder.ondataavailable = (e) => chunks.push(e.data);

        recorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });

          if (blob.size === 0) {
            textArea.value = 'âŒ No audio recorded.';
            return;
          }

          const form = new FormData();
          form.append('file', blob, 'audio.webm');

          try {
            const res = await fetch('https://fyp-2025-kath.vercel.app/api/analyze', {
              method: 'POST',
              body: form,
            });

            const result = await res.json();
            textArea.value = result.summary || result.transcript || JSON.stringify(result, null, 2);

            // å‘ Figma æ’ä»¶å‘é€åˆ†æç»“æœ
            window.parent?.postMessage({
              pluginMessage: {
                type: 'analyze-transcript',
                transcript: result.transcript,
                summary: result.summary
              }
            }, '*');
          } catch (err) {
            console.error('âŒ Fetch or server error:', err);
            textArea.value = 'âŒ Error: ' + err.message;
          }

          startBtn.disabled = false;
          stopBtn.disabled = true;
        };

        recorder.start();
        textArea.value = 'ğŸ™ï¸ Recording...';
        startBtn.disabled = true;
        stopBtn.disabled = false;
      } catch (err) {
        console.error('âŒ Could not access microphone:', err);
        textArea.value = 'âŒ Microphone access error.';
      }
    }

    function stopRecording() {
      if (recorder && recorder.state === 'recording') {
        recorder.stop();
      }
    }
  </script>
</body>
</html> -->

<!-- <!DOCTYPE html>
<html>
<head><meta charset="utf-8"><title>Recorder</title></head>
<body>
  <h2>ğŸ¤ Recorder</h2>
  <button id="start">Start</button>
  <button id="stop" disabled>Stop & Analyze</button>
  <textarea id="text" style="width:100%;height:150px;"></textarea>

  <script>
    let recorder, chunks = [];

    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const textArea = document.getElementById('text');

    startBtn.onclick = async () => {
      chunks = []; // æ¸…ç©ºæ—§æ•°æ®
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recorder = new MediaRecorder(stream);

      recorder.ondataavailable = e => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      recorder.start();
      startBtn.disabled = true;
      stopBtn.disabled = false;
    };

    stopBtn.onclick = () => {
      recorder.stop();

      recorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });

        if (blob.size === 0) {
          textArea.value = 'âŒ No audio recorded.';
          return;
        }

        const form = new FormData();
        form.append('file', blob, 'audio.webm'); // âœ… ä¿æŒå­—æ®µåä¸º 'file'

        try {
          const res = await fetch('https://fyp-2025-kath.vercel.app/api/analyze', { method: 'POST', body: form });

          if (!res.ok) {
            const errorText = await res.text();
            console.error('âŒ Server error:', errorText);
            textArea.value = 'âŒ Server error: ' + errorText;
            return;
          }

          const result = await res.json();
          textArea.value = result.summary || result.transcript || JSON.stringify(result, null, 2);
          //window.parent?.postMessage({ pluginMessage: json }, '*');
          window.parent?.postMessage({
            pluginMessage: {
              type: 'analyze-transcript',
              transcript: result.transcript,
              summary: result.summary,
            }
          }, '*');
        } catch (err) {
          console.error('âŒ Network or fetch error:', err);
          textArea.value = 'âŒ Fetch error: ' + err.message;
        }

        startBtn.disabled = false;
        stopBtn.disabled = true;
      };
    };
  </script>
</body>
</html> -->


<!-- <!DOCTYPE html>
<html>
<head><meta charset="utf-8"><title>Recorder</title></head>
<body>
  <h2>ğŸ¤ Recorder</h2>
  <button id="start">Start</button>
  <button id="stop" disabled>Stop & Analyze</button>
  <textarea id="text" style="width:100%;height:150px;"></textarea>

  <script>
    let recorder, chunks = [];
    document.getElementById('start').onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recorder = new MediaRecorder(stream);
      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.start();
      document.getElementById('start').disabled = true;
      document.getElementById('stop').disabled = false;
    };

    document.getElementById('stop').onclick = () => {
      recorder.stop();
      recorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        const form = new FormData();
        form.append('file', blob, 'audio.webm');
        const res = await fetch('/api/analyze', { method: 'POST', body: form });
        if (!res.ok) {
          const text = await res.text(); // ç”¨ text çœ‹é”™è¯¯ç»†èŠ‚
          console.error('âŒ Server error:', text);
          document.getElementById('text').value = 'âŒ Server error: ' + text;
          return;}
        const json = await res.json();
        document.getElementById('text').value = JSON.stringify(json, null, 2);
        window.parent.postMessage({ pluginMessage: json }, '*');
        document.getElementById('start').disabled = false;
        document.getElementById('stop').disabled = true;
      };
    };
  </script>
</body>
</html> -->



<!-- <h2>ğŸ¤ External Recorder</h2>
<button id="start">Start Recording</button>
<button id="stop" disabled>Stop</button>
<textarea id="text" placeholder="Transcript will appear here..."></textarea>
<script>
  let recognition;
  let finalTranscript = '';

  if (!('webkitSpeechRecognition' in window)) {
    alert("Please use Google Chrome.");
  } else {
    recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    recognition.onresult = (event) => {
      let interim = '';
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        if (event.results[i].isFinal) {
          finalTranscript += event.results[i][0].transcript;
        } else {
          interim += event.results[i][0].transcript;
        }
      }
      document.getElementById('text').value = finalTranscript + interim;
    };

    recognition.onerror = (e) => {
      console.error("Speech recognition error:", e);
      alert("Microphone access denied or blocked.");
    };
  }

  document.getElementById('start').onclick = () => {
    finalTranscript = '';
    recognition.start();
    document.getElementById('start').disabled = true;
    document.getElementById('stop').disabled = false;
  };

  document.getElementById('stop').onclick = () => {
    recognition.stop();
    document.getElementById('start').disabled = false;
    document.getElementById('stop').disabled = true;
    const text = document.getElementById('text').value;

    window.parent.postMessage({
      pluginMessage: {
        type: 'analyze-transcript',
        text: text
      }
    }, '*');

    alert("âœ… Sent transcript to plugin UI.");
  };
</script> -->



<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ğŸ¤ Recorder</title>
  <style>
    body {
      font-family: sans-serif;
      padding: 20px;
    }
    button {
      padding: 10px 20px;
      margin: 10px 0;
    }
    textarea {
      width: 100%;
      height: 150px;
    }
  </style>
</head>
<body>
  <h2>ğŸ¤ External Recorder</h2>
  <button id="start">Start Recording</button>
  <button id="stop" disabled>Stop</button>
  <textarea id="text" placeholder="Transcript will appear here..."></textarea>

  <script>
    let recognition;
    let finalTranscript = '';

    if (!('webkitSpeechRecognition' in window)) {
      alert("Please use Google Chrome to use this feature.");
    } else {
      recognition = new webkitSpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onresult = (event) => {
        let interim = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript;
          } else {
            interim += event.results[i][0].transcript;
          }
        }
        document.getElementById('text').value = finalTranscript + interim;
      };

      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e);
        alert("Microphone access denied or blocked.");
      };
    }

    document.getElementById('start').onclick = () => {
      finalTranscript = '';
      recognition.start();
      document.getElementById('start').disabled = true;
      alert("ğŸ“¤ start shdshh transcript to UI: " + text);
      document.getElementById('stop').disabled = false;
    };

    document.getElementById('stop').onclick = () => {
  // âœ… è·å–è½¬å½•æ–‡æœ¬
  const text = document.getElementById('text').value;

  // âœ… åœæ­¢å½•éŸ³ & æŒ‰é’®åˆ‡æ¢
  recognition.stop();
  document.getElementById('start').disabled = false;
  document.getElementById('stop').disabled = true;

  // âœ… æ‰“å°ç¡®è®¤
  console.log("ğŸ“¤ About to send transcript to parent iframe:", text);

  // âœ… ä½¿ç”¨ window.parent å‘é€ç»™çˆ¶çª—å£ï¼ˆui.htmlï¼‰
  window.parent.postMessage({
    pluginMessage: {
      type: 'analyze-transcript',
      text: text
    }
  }, '*');

  alert("âœ… Sent transcript to plugin UI.");
}; -->


