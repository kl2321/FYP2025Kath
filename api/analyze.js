// import { IncomingForm } from 'formidable';
// import fs from 'fs';
// import axios from 'axios';
// import FormData from 'form-data';

// export const config = {
//   api: {
//     bodyParser: false,
//   },
// };

// export default async function handler(req, res) {
//   if (req.method !== 'POST') {
//     return res.status(405).json({ error: 'Method not allowed' });
//   }

//   const form = new IncomingForm({
//     uploadDir: '/tmp',
//     keepExtensions: true,
//   });

//   form.parse(req, async (err, fields, files) => {
//     if (err) {
//       console.error('âŒ Form parse error:', err);
//       return res.status(500).json({ error: 'Form parse error', detail: err.message });
//     }

//     const rawFile = Array.isArray(files.file) ? files.file[0] : files.file;
//     if (!rawFile || !rawFile.filepath) {
//       return res.status(400).json({ error: 'Audio file is missing' });
//     }

//     const openAIKey = process.env.OPENAI_API_KEY;
//     if (!openAIKey) {
//       return res.status(500).json({ error: 'Missing OpenAI API key' });
//     }

//     try {
//       // âœ… Whisper API with axios + form-data
//       const formData = new FormData();
//       formData.append('file', fs.createReadStream(rawFile.filepath));
//       formData.append('model', 'whisper-1');

//       console.log('ðŸ“¤ Sending to Whisper...');
//       const whisperRes = await axios.post(
//         'https://api.openai.com/v1/audio/transcriptions',
//         formData,
//         {
//           headers: {
//             Authorization: `Bearer ${openAIKey}`,
//             ...formData.getHeaders(), // ðŸ‘ˆ åŒ…å« multipart boundary
//           },
//         }
//       );

//       const transcript = whisperRes.data.text;
//       console.log('âœ… Whisper transcript:', transcript);

//       // ðŸ” GPT summary
//       const gptRes = await axios.post(
//         'https://api.openai.com/v1/chat/completions',
//         {
//           model: 'gpt-4o-mini',
//           //messages: [{ role: 'user', content: `please summarize the following and split into explicit and tacit knowledge:\n\n${transcript}` }],
//           messages: [{
//             role: 'user',
//             content: `Please summarize the following meeting transcript and split the content into explicit and tacit knowledge. Only include conversation related to the team's project work or collaboration.\n\n- Explicit knowledge refers to documented, factual information such as data, specifications, or user feedback.\n- Tacit knowledge refers to intuitive insights, experience-based observations, or subjective impressions shared by team members.\n\nSummarize the conversation and categorize the relevant points into the two types.\n\nTranscript:\n\n${transcript}`
//           }]
//         },
//         {
//           headers: {
//             Authorization: `Bearer ${openAIKey}`,
//             'Content-Type': 'application/json',
//           },
//         }
//       );

//       return res.status(200).json({
//         transcript,
//         summary: gptRes.data.choices[0].message.content,
//       });
//     } catch (err) {
//       console.error(' Error during processing:', err?.response?.data || err.message);
//       return res.status(500).json({
//         error: 'Processing failed',
//         detail: err?.response?.data || err.message,
//       });
//     }
//   });
// }

// api/analyze.js
// éŸ³é¢‘å¤„ç†ä¸­å¿ƒ - æŽ¥æ”¶éŸ³é¢‘å—ï¼Œè½¬å½•å¹¶åˆ†æž

import { IncomingForm } from 'formidable';
import fs from 'fs';
import axios from 'axios';
import FormData from 'form-data';

// å¼•å…¥é›†ä¸­é…ç½®
const config = require('../lib/config');

// Verceléœ€è¦è¿™ä¸ªé…ç½®æ¥å¤„ç†æ–‡ä»¶ä¸Šä¼ 
export const apiConfig = {
  api: {
    bodyParser: false,  // ç¦ç”¨é»˜è®¤çš„bodyè§£æžï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†æ–‡ä»¶ä¸Šä¼ 
  },
};

export default async function handler(req, res) {
  // æ·»åŠ CORSå¤´éƒ¨
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
  
  // å¤„ç†OPTIONSè¯·æ±‚
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }
  
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // æ£€æŸ¥OpenAIé…ç½®
  if (!config.openai.apiKey) {
    console.error('OpenAI API key not configured');
    return res.status(500).json({ error: 'Server configuration error: Missing OpenAI API key' });
  }

  // åˆ›å»ºè¡¨å•è§£æžå™¨æ¥å¤„ç†æ–‡ä»¶ä¸Šä¼ 
  const form = new IncomingForm({
    uploadDir: '/tmp',        // Vercelçš„ä¸´æ—¶æ–‡ä»¶ç›®å½•
    keepExtensions: true,     // ä¿ç•™æ–‡ä»¶æ‰©å±•å
    maxFileSize: 50 * 1024 * 1024,  // 50MBé™åˆ¶
  });

  // è§£æžä¸Šä¼ çš„è¡¨å•æ•°æ®
  form.parse(req, async (err, fields, files) => {
    if (err) {
      console.error('âŒ Form parse error:', err);
      return res.status(500).json({ 
        error: 'Form parse error', 
        detail: config.isDevelopment ? err.message : undefined 
      });
    }

    // èŽ·å–ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
    const rawFile = Array.isArray(files.file) ? files.file[0] : files.file;
    if (!rawFile || !rawFile.filepath) {
      return res.status(400).json({ error: 'Audio file is missing' });
    }

    console.log('ðŸ“ Received audio file:', {
      name: rawFile.originalFilename,
      size: rawFile.size,
      type: rawFile.mimetype
    });

    try {
      // ========== Step 1: éŸ³é¢‘è½¬æ–‡å­— (Whisper) ==========
      const formData = new FormData();
      formData.append('file', fs.createReadStream(rawFile.filepath));
      formData.append('model', config.openai.whisperModel || 'whisper-1');
      
      // å¯é€‰ï¼šæ·»åŠ è¯­è¨€æç¤º
      // formData.append('language', 'en'); // æˆ– 'zh' ä¸­æ–‡

      console.log('ðŸ”¤ Sending to Whisper API...');
      
      const whisperRes = await axios.post(
        `${config.openai.apiUrl}/audio/transcriptions`,
        formData,
        {
          headers: {
            Authorization: `Bearer ${config.openai.apiKey}`,
            ...formData.getHeaders(), // åŒ…å« multipart boundary
          },
          timeout: 60000, // 60ç§’è¶…æ—¶
        }
      );

      const transcript = whisperRes.data.text;
      console.log('âœ… Whisper transcript received, length:', transcript.length);

      // ========== Step 2: æ–‡æœ¬åˆ†æž (GPT) ==========
      
      // æž„å»ºåˆ†æžæç¤ºè¯
      const systemPrompt = `You are a meeting assistant analyzing team discussions. 
      Focus on project-related content and collaboration.
      Categorize insights into explicit knowledge (documented facts) and tacit knowledge (experiential insights).`;
      
      const userPrompt = `Please summarize the following meeting transcript and split the content into explicit and tacit knowledge.

Only include conversation related to the team's project work or collaboration.

- Explicit knowledge refers to documented, factual information such as data, specifications, or user feedback.
- Tacit knowledge refers to intuitive insights, experience-based observations, or subjective impressions shared by team members.

Summarize the conversation and categorize the relevant points into the two types.

Transcript:

${transcript}`;

      console.log('ðŸ¤– Sending to GPT for analysis...');
      
      const gptRes = await axios.post(
        `${config.openai.apiUrl}/chat/completions`,
        {
          model: 'gpt-4o-mini', // ä½¿ç”¨è¾ƒå¿«çš„æ¨¡åž‹å¤„ç†å®žæ—¶è½¬å½•
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.3,  // è¾ƒä½Žçš„æ¸©åº¦ä½¿è¾“å‡ºæ›´ä¸€è‡´
          max_tokens: 500,   // é™åˆ¶å“åº”é•¿åº¦
        },
        {
          headers: {
            Authorization: `Bearer ${config.openai.apiKey}`,
            'Content-Type': 'application/json',
          },
          timeout: 30000, // 30ç§’è¶…æ—¶
        }
      );

      // æ£€æŸ¥GPTå“åº”
      if (!gptRes.data?.choices?.[0]?.message?.content) {
        console.warn('âš ï¸ GPT returned empty response');
        return res.status(200).json({
          transcript,
          summary: 'Unable to generate summary',
        });
      }

      const summary = gptRes.data.choices[0].message.content;
      console.log('âœ… GPT analysis complete');

      // ========== Step 3: æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ==========
      try {
        fs.unlinkSync(rawFile.filepath);
        console.log('ðŸ—‘ï¸ Temporary file cleaned up');
      } catch (cleanupErr) {
        console.warn('Failed to clean up temp file:', cleanupErr.message);
      }

      // ========== Step 4: è¿”å›žç»“æžœ ==========
      return res.status(200).json({
        success: true,
        transcript,
        summary,
        metadata: {
          audioSize: rawFile.size,
          transcriptLength: transcript.length,
          processedAt: new Date().toISOString(),
        }
      });
      
    } catch (err) {
      console.error('âŒ Error during processing:', err?.response?.data || err.message);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try {
        fs.unlinkSync(rawFile.filepath);
      } catch (cleanupErr) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      
      // æ ¹æ®é”™è¯¯ç±»åž‹è¿”å›žä¸åŒçš„å“åº”
      if (err.response?.status === 401) {
        return res.status(500).json({
          error: 'Authentication failed',
          detail: 'Invalid or missing API key'
        });
      }
      
      if (err.response?.status === 429) {
        return res.status(429).json({
          error: 'Rate limit exceeded',
          detail: 'Too many requests, please try again later'
        });
      }
      
      // åœ¨å¼€å‘çŽ¯å¢ƒè¿”å›žè¯¦ç»†é”™è¯¯
      if (config.isDevelopment) {
        return res.status(500).json({
          error: 'Processing failed',
          detail: err?.response?.data || err.message,
          stack: err.stack
        });
      }
      
      // ç”Ÿäº§çŽ¯å¢ƒè¿”å›žé€šç”¨é”™è¯¯
      return res.status(500).json({
        error: 'Processing failed',
        detail: 'An error occurred while processing the audio'
      });
    }
  });
}

// ========== æ³¨é‡ŠæŽ‰çš„ AssemblyAI ä»£ç è¯´æ˜Ž ==========
/*
æ‚¨çš„ä»£ç ä¸­æœ‰æ³¨é‡ŠæŽ‰çš„ AssemblyAI å®žçŽ°ï¼Œè¿™æ˜¯å¦ä¸€ç§éŸ³é¢‘å¤„ç†æ–¹æ¡ˆï¼š

AssemblyAI ä¼˜åŠ¿ï¼š
1. æ”¯æŒè¯´è¯äººåˆ†ç¦»ï¼ˆspeaker diarizationï¼‰- å¯ä»¥è¯†åˆ«ä¸åŒçš„è¯´è¯äºº
2. æ›´å‡†ç¡®çš„é•¿éŸ³é¢‘è½¬å½•
3. æ”¯æŒå¤šç§è¯­è¨€è‡ªåŠ¨æ£€æµ‹

å¦‚æžœå°†æ¥éœ€è¦è¯´è¯äººåˆ†ç¦»åŠŸèƒ½ï¼Œå¯ä»¥ï¼š
1. åœ¨ Vercel æ·»åŠ  ASSEMBLYAI_API_KEY
2. åœ¨ config.js æ·»åŠ  AssemblyAI é…ç½®
3. å¯ç”¨æ³¨é‡Šçš„ä»£ç 

å½“å‰ä½¿ç”¨ OpenAI Whisper çš„åŽŸå› ï¼š
1. ç»Ÿä¸€ä½¿ç”¨ OpenAI æœåŠ¡ï¼Œå‡å°‘ä¾èµ–
2. Whisper å¯¹çŸ­éŸ³é¢‘ï¼ˆ30ç§’ç‰‡æ®µï¼‰æ•ˆæžœå¾ˆå¥½
3. æˆæœ¬æ›´ä½Žï¼Œé›†æˆæ›´ç®€å•
*/







// // /api/analyze.js  â€”â€” AssemblyAI (speaker diarization), no GPT
// import { IncomingForm } from 'formidable';
// import fs from 'fs';
// import axios from 'axios';

// export const config = { api: { bodyParser: false } };

// // AssemblyAI endpoints
// const AAI_KEY = process.env.ASSEMBLYAI_API_KEY;
// const AAI_UPLOAD = 'https://api.assemblyai.com/v2/upload';
// const AAI_TRANSCRIPT = 'https://api.assemblyai.com/v2/transcript';

// export default async function handler(req, res) {
//   if (req.method !== 'POST') return res.status(405).json({ error: 'Method not allowed' });
//   if (!AAI_KEY) return res.status(500).json({ error: 'Missing ASSEMBLYAI_API_KEY' });

//   const form = new IncomingForm({ uploadDir: '/tmp', keepExtensions: true });

//   form.parse(req, async (err, fields, files) => {
//     if (err) {
//       console.error('âŒ Form parse error:', err);
//       return res.status(500).json({ error: 'Form parse error', detail: err.message });
//     }

//     const rawFile = Array.isArray(files.file) ? files.file[0] : files.file;
//     if (!rawFile?.filepath) return res.status(400).json({ error: 'Audio file is missing' });

//     try {
//       // 1) Upload audio bytes to AssemblyAI
//       const uploadRes = await axios.post(
//         AAI_UPLOAD,
//         fs.createReadStream(rawFile.filepath),
//         {
//           headers: { authorization: AAI_KEY, 'content-type': 'application/octet-stream' },
//           maxContentLength: Infinity,
//           maxBodyLength: Infinity,
//           timeout: 60_000
//         }
//       );

//       // 2) Create transcript with speaker labels
//       const createRes = await axios.post(
//         AAI_TRANSCRIPT,
//         {
//           audio_url: uploadRes.data.upload_url,
//           speaker_labels: true,      // ðŸ‘ˆ å…³é”®ï¼šå¼€å¯è¯´è¯äººåˆ†ç¦»
//           punctuate: true,
//           format_text: true,
//           // language_code: 'en_us'   // å¯é€‰
//         },
//         { headers: { authorization: AAI_KEY }, timeout: 30_000 }
//       );

//       const jobId = createRes.data.id;

//       // 3) Poll until completed
//       const tr = await pollAAI(jobId);

//       // 4) Build utterances + labeled transcript
//       const utterances = normalizeUtterances(tr?.utterances || []);
//       const transcript = utterances.length
//         ? utterances.map(u => `${u.speaker_label}: ${u.text}`).join('\n')
//         : (tr?.text || '');

//       return res.status(200).json({
//         provider: 'assemblyai',
//         duration_sec: tr?.audio_duration || null,
//         transcript,
//         utterances
//       });

//     } catch (e) {
//       const detail = e?.response?.data || e?.message || String(e);
//       console.error('ðŸ”¥ analyze error:', detail);
//       return res.status(500).json({ error: 'Processing failed', detail });
//     } finally {
//       try { fs.unlinkSync(rawFile.filepath); } catch {}
//     }
//   });
// }

// // ---- Helpers ----
// async function pollAAI(id) {
//   const headers = { authorization: AAI_KEY };
//   const maxAttempts = 100; // ~150s
//   for (let i = 0; i < maxAttempts; i++) {
//     await sleep(1500);
//     try {
//       const r = await axios.get(`${AAI_TRANSCRIPT}/${id}`, { headers, timeout: 25_000 });
//       const data = r.data || {};
//       if (data.status === 'completed') return data;
//       if (data.status === 'error') throw new Error(data.error || 'AAI error');
//       // queued / processing -> continue
//     } catch (e) {
//       if (i > 5) console.warn(`Polling #${i} error`, e?.message || e);
//     }
//   }
//   throw new Error('Timeout polling transcript');
// }

// function normalizeUtterances(raw = []) {
//   // AAI çš„ speaker å¸¸è§ä¸º 'A','B','C'...ï¼›ä¹Ÿå¯èƒ½æ˜¯æ•°å­—ï¼Œç»Ÿä¸€æˆ SPEAKER_X
//   return raw.map(u => ({
//     speaker_label: `SPEAKER_${u.speaker ?? 'X'}`,
//     start_ms: Math.round((u.start || 0) * 1000),
//     end_ms: Math.round((u.end || 0) * 1000),
//     text: u.text || ''
//   }));
// }

// function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }
